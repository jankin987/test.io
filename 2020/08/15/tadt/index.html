<!-- - var pageTitle = page.title || config.subtitle || ''--><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="TADT"><meta name="keywords" content="Siamese network,VGG-16"><meta name="author" content="Soarkey,soarkey@foxmail.com"><meta name="copyright" content="Soarkey"><title>TADT | Soarkey's Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#abstract"><span class="toc-text"> Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-introduction"><span class="toc-text"> 1. Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-method"><span class="toc-text"> 2. Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#21-features-of-the-pre-trained-cnns"><span class="toc-text"> 2.1 Features of the pre-trained CNNs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-target-active-features-via-regression"><span class="toc-text"> 2.2 Target-Active Features via Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-scale-sensitive-features-via-ranking"><span class="toc-text"> 2.3 Scale-Sensitive Features via Ranking</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-tracking-process"><span class="toc-text"> 3. Tracking Process</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#31-tracker-initialization"><span class="toc-text"> 3.1 Tracker initialization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#32-online-detection"><span class="toc-text"> 3.2 Online detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#33-scale-evaluation"><span class="toc-text"> 3.3 Scale evaluation</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-experiments"><span class="toc-text"> 4. Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#41-results"><span class="toc-text"> 4.1 Results</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#42-ablation-studies"><span class="toc-text"> 4.2 Ablation Studies</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars3.githubusercontent.com/u/17349395?s=400&amp;u=b4d8f5e790e0fab115d7237ee3404f24813e115b&amp;v=4"></div><div class="author-info__name text-center">Soarkey</div><div class="author-info__description text-center">Soarkey's Blog</div><div class="follow-button"><a href="https://github.com/Soarkey">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">16</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">15</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">13</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://github.com/Soarkey">github</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://github.com/Soarkey/soarkey.github.io/blob/master/img/bg.png?raw=true)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Soarkey's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">TADT</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-08-15</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Siamese-network/">Siamese network</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">775</span><span class="post-meta__separator">|</span><span>Reading time: 4 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><blockquote>
<p><img src="/2020/08/15/tadt/image-20200814163023573.png" alt="author"></p>
<p>ğŸ“„ paper: <a href="https://arxiv.org/pdf/1904.01772.pdf">https://arxiv.org/pdf/1904.01772.pdf</a></p>
<p>ğŸ’» code: <a href="https://github.com/ZikunZhou/TADT-python">https://github.com/ZikunZhou/TADT-python</a></p>
<p>ğŸŒŸ  CVPR 2019</p>
</blockquote>
<a id="more"></a>
<h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1>
<p>[æå‡ºå¯¹é¢„è®­ç»ƒæ¨¡å‹çš„è´¨ç–‘ï¼Œå…³æ³¨ç‰¹å¾æå–çš„éƒ¨åˆ†]</p>
<p>â€‹	Despite demonstrated successes for numerous vision tasks, the contributions of using pre-trained deep features for visual tracking are not as significant as<br>
that for object recognition.</p>
<p><strong>key issue :</strong></p>
<ul>
<li>
<p>in visual tracking, the targets of interest can be <mark>arbitrary object class with arbitrary forms</mark>.</p>
</li>
<li>
<p>pre-trained deep features are less effective in modeling these targets of arbitrary forms for distinguishing them from the background.</p>
</li>
</ul>
<p><strong>Contribution:</strong></p>
<ul>
<li>a novel scheme to learn <mark>target-aware features</mark>.<br>
(which can better recognize the targets undergoing significant appearance variations than pre-trained deep features.)</li>
<li>develop a <mark>regression loss</mark> and a <mark>ranking loss</mark> to guide the generation of <mark>target-active and scale-sensitive features</mark>.</li>
</ul>
<blockquote>
<p>æ˜¯å¦å¯ä»¥ç†è§£ä¸ºæœ¬è´¨ä¸Šæ˜¯é€šé“é—´çš„æ³¨æ„åŠ›ï¼Ÿ</p>
</blockquote>
<h1 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction"></a> 1. Introduction</h1>
<p><strong>target:</strong> learn target-aware deep features.</p>
<p>â€‹	The gradients obtained through back-propagating a classification neural network indicate <mark>class-specific saliency well</mark>[33]. (ç‰¹å®šç±»åˆ«çš„æ˜¾è‘—æ€§)  With the use of <strong>global average pooling</strong>, the gradients generated by a convolutional filter can determine the importance of a filter for representing target objects.</p>
<blockquote>
<p>[33]ï¼š Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</p>
<ul>
<li>
<p>paper: <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf</a></p>
</li>
<li>
<p>supp: <a href="https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_supplemental.zip">https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_supplemental.zip</a></p>
</li>
<li>
<p>code:  <a href="https://github.com/ramprs/grad-cam/">https://github.com/ramprs/grad-cam/</a></p>
</li>
<li>
<p>blog: <a href="https://blog.csdn.net/u013738531/article/details/81322043">https://blog.csdn.net/u013738531/article/details/81322043</a></p>
</li>
</ul>
  <img src="/2020/08/15/tadt/687474703a2f2f692e696d6775722e636f6d2f4a614762645a352e706e67.jpg" alt="Grad-CAM framework" style="zoom: 50%;">
  <img src="/2020/08/15/tadt/image-20200815145435355.png" alt="Grad-CAM" style="zoom:70%;">
</blockquote>
<p><strong>two types of objective losses:</strong></p>
<ul>
<li><strong>hinge loss</strong><br>
to regress pre-trained deep features to soft labels generated by a Gaussian function,<br>
use the gradients to select the target-active convolutional filters.</li>
<li><strong>ranking loss</strong><br>
with pair-wise distance to search for the scale-aware convolutional filters.</li>
</ul>
<p><strong>target-aware features vs. original deep features:</strong></p>
<blockquote>
<p>è¿™ä¸ªç»˜å›¾çš„æ€è·¯å¾ˆç‰¹åˆ«ï¼Œä½¿ç”¨äº†t-SNEé™ç»´ã€‚</p>
<p>target-awareå¯ä»¥æ‰©å¤§ç±»å†…å’Œç±»é—´çš„è·ç¦»ï¼ˆå³åŒºåˆ†åº¦æ›´é«˜ï¼‰</p>
</blockquote>
<p><img src="/2020/08/15/tadt/image-20200815150801070.png" alt="target-aware features vs. original deep features"></p>
<h1 id="2-method"><a class="markdownIt-Anchor" href="#2-method"></a> 2. Method</h1>
<h2 id="21-features-of-the-pre-trained-cnns"><a class="markdownIt-Anchor" href="#21-features-of-the-pre-trained-cnns"></a> 2.1 Features of the pre-trained CNNs</h2>
<p><strong>issues:</strong></p>
<ul>
<li>the pre-trained CNN features are agnostic of the semantic and objectness information of  the target, which most likely does not appear in the offline training data. (è¿½è¸ªéœ€è¦å¤„ç†ä»»ä½•å¯¹è±¡æ ‡ç­¾çš„ç›®æ ‡)</li>
<li>the pre-trained CNNs focus on increasing inter-class differences and the extracted deep features are insensitive to intra-class variations. ï¼ˆå¯¹ç±»é—´çš„ä¸åŒæ›´æ•æ„Ÿï¼Œå¯¹ç±»å†…çš„å˜åŒ–ä¸æ•æ„Ÿï¼‰</li>
<li>the pre-trained deep features are sparsely activated by each category label especially in a deeper convolutional network. ï¼ˆé¢„è®­ç»ƒçš„æ·±åº¦ç‰¹å¾è¢«æ¯ä¸ªç±»åˆ«æ ‡ç­¾ç¨€ç–æ¿€æ´»ï¼Œå³ç±»åˆ«é—´çš„å·®å¼‚ä¸»è¦å’Œå°‘æ•°ç‰¹å¾æœ‰å…³ï¼›å½“ç”¨äºè¿½è¸ªæ—¶ï¼Œåªæœ‰å°‘éƒ¨åˆ†è¢«æ¿€æ´»ï¼Œä¼šå¢åŠ è®¡ç®—é‡ï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆï¼‰</li>
</ul>
<p>â€‹	Based on the <mark>gradient-based guidance</mark>, we construct a target-aware feature model with losses designed specifically for visual tracking.</p>
<h2 id="22-target-active-features-via-regression"><a class="markdownIt-Anchor" href="#22-target-active-features-via-regression"></a> 2.2 Target-Active Features via Regression</h2>
<p><img src="/2020/08/15/tadt/image-20200815161519345.png" alt="formula"></p>
<p><img src="/2020/08/15/tadt/image-20200815161545940.png" alt="formula"></p>
<p>å¦‚Fig.4Â©</p>
<p><img src="/2020/08/15/tadt/image-20200815161443754.png" alt="visualization"></p>
<h2 id="23-scale-sensitive-features-via-ranking"><a class="markdownIt-Anchor" href="#23-scale-sensitive-features-via-ranking"></a> 2.3 Scale-Sensitive Features via Ranking</h2>
<p><img src="/2020/08/15/tadt/image-20200815164732365.png" alt="formula"></p>
<p><img src="/2020/08/15/tadt/image-20200815164756633.png" alt="formula"></p>
<p><img src="/2020/08/15/tadt/image-20200815164830005.png" alt="formula"></p>
<h1 id="3-tracking-process"><a class="markdownIt-Anchor" href="#3-tracking-process"></a> 3. Tracking Process</h1>
<p><strong>overall framework:</strong></p>
<p><img src="/2020/08/15/tadt/image-20200815155629771.png" alt="architecture"></p>
<h2 id="31-tracker-initialization"><a class="markdownIt-Anchor" href="#31-tracker-initialization"></a> 3.1 Tracker initialization</h2>
<ul>
<li>The pre-trained feature extractor is offline trained on the classification task.</li>
<li><mark>the target-aware part is only trained in the first frame.</mark></li>
</ul>
<p>â€‹	In initial training, the regression loss and the ranking loss parts are trained separately and we compute the gradients from each loss once the networks are converged. With the gradients, the feature generation model selects a fixed number of the filters with the highest importance scores from the pre-trained CNNs.</p>
<p>â€‹	The final target-aware features are obtained by stacking these two types of feature filters. Considering the scalar difference, these two types of features are <mark>re-scaled by dividing their maximal channel summation</mark> (summation of all the values in one channel).</p>
<blockquote>
<p>å…·ä½“æ“ä½œå­˜åœ¨ç–‘é—®</p>
</blockquote>
<h2 id="32-online-detection"><a class="markdownIt-Anchor" href="#32-online-detection"></a> 3.2 Online detection</h2>
<p><img src="/2020/08/15/tadt/image-20200815170343327.png" alt="formula"></p>
<h2 id="33-scale-evaluation"><a class="markdownIt-Anchor" href="#33-scale-evaluation"></a> 3.3 Scale evaluation</h2>
<p>â€‹	To evaluate the scale change of the target, we fix the size of the template and re-scale the feature map of the search region in the current frame to smaller,<br>
larger, and fixed ones. During tracking, all these three feature maps are compared with the target template. The scale evaluation is performed by finding the score map containing the highest response.</p>
<h1 id="4-experiments"><a class="markdownIt-Anchor" href="#4-experiments"></a> 4. Experiments</h1>
<h2 id="41-results"><a class="markdownIt-Anchor" href="#41-results"></a> 4.1 Results</h2>
<p><img src="/2020/08/15/tadt/image-20200815195043731.png" alt="experiments"></p>
<p><img src="/2020/08/15/tadt/image-20200815195144776.png" alt="OTB"></p>
<p><img src="/2020/08/15/tadt/image-20200815195210762.png" alt="VOT"></p>
<p><img src="/2020/08/15/tadt/image-20200815195235715.png" alt="TC-128"></p>
<h2 id="42-ablation-studies"><a class="markdownIt-Anchor" href="#42-ablation-studies"></a> 4.2 Ablation Studies</h2>
<p><img src="/2020/08/15/tadt/image-20200815195330938.png" alt="ablation study"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:soarkey@foxmail.com">Soarkey</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://soarkey.github.io/2020/08/15/tadt/">http://soarkey.github.io/2020/08/15/tadt/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Siamese-network/">Siamese network</a><a class="post-meta__tags" href="/tags/VGG-16/">VGG-16</a></div><div class="social-share pull-right"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/08/23/dasiamrpn/"><i class="fa fa-chevron-left">  </i><span>DaSiamRPN</span></a></div><div class="next-post pull-right"><a href="/2020/08/09/ocean/"><span>Ocean</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'c1c26b093ab018134968',
  clientSecret: 'b85a3a9d5e48dfc88343b4f40fced48e46e522e0',
  repo: 'soarkey.github.io',
  owner: 'Soarkey',
  admin: 'Soarkey',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://github.com/Soarkey/soarkey.github.io/blob/master/img/bg.png?raw=true)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2020 By Soarkey</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.2" zIndex="-1" data-click="true"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>